# -*- coding: utf-8 -*-
"""SoccerTweetAnalysis.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1OuZCJ6RhdowUir7SxbI4LSuWutMKlh6K

## Part 1: Analyzing Tweets About Countries in Spark
"""

!pip install pyspark
!pip install -U -q PyDrive
!apt install openjdk-8-jdk-headless -qq
import os
os.environ["JAVA_HOME"] = "/usr/lib/jvm/java-8-openjdk-amd64"

# Commented out IPython magic to ensure Python compatibility.
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
# %matplotlib inline

import pyspark
from pyspark.sql import *
from pyspark.sql.functions import *
from pyspark import SparkContext, SparkConf

# create the session
conf = SparkConf().set("spark.ui.port", "4050")

# create the context
sc = pyspark.SparkContext(conf=conf)
spark = SparkSession.builder.getOrCreate()

from pyspark import SparkContext
sc =SparkContext.getOrCreate()
spark = SparkSession.builder.getOrCreate()

# Import and create a new SQLContext 
from pyspark.sql import SQLContext
sqlContext = SQLContext(sc)

country_lines = sc.textFile('country-list.csv')

# Convert each line into a pair of words
word = country_lines.flatMap(lambda line: line.split("\n"))

# Convert each pair of words into a tuple
tuples = word.map(lambda line:tuple(line.split(",")))

# Create the DataFrame, look at schema and contents
countryDF = sqlContext.createDataFrame(tuples, ["country", "code"])
countryDF.printSchema()
countryDF.take(3)

countryDF.show(3)

# Read tweets JSON file spark.read.json
tweet_data = spark.read.json("/content/drive/MyDrive/Assignment02/users.json")
tweet_data.printSchema()
tweet_data.show(3)

tweet_text = tweet_data.drop('_id', 'coordinates', 'retweet_count', 'source', 'tweet_ID', 'tweet_followers_count', 'tweet_mentioned_count', 'user', 'user_name' )
tweet_text.printSchema()
tweet_text.show(3)

tweet_text_rdd = tweet_text.rdd

# Clean the data: some tweets are empty. Remove the empty tweets using filter() 
clean_tweet_texts = tweet_text.rdd.filter(lambda x : len(x) > 0)
clean_tweet_texts.count()

# Perform WordCount on the cleaned tweet texts. (note: this is several lines.)
tweet_words = clean_tweet_texts.flatMap(lambda line: line.split(" "))
tweet_tuples  = tweet_words.map(lambda word : (word, 1))
word_counts = tweet_tuples.reduceByKey(lambda a, b :(a + b))

# Create the DataFrame of tweet word counts
tweetDF = sqlContext.createDataFrame(word_counts, ["word", "count"])
tweetDF.printSchema()
tweetDF.take(10)

"""###Working other way arround. This time reading file as sc.textFile RDD"""

twet_data = sc.textFile("users.json")
twet_data.count()

# Clean the data: some tweets are empty. Remove the empty tweets using filter() 
clean_twet_texts = twet_data.filter(lambda x : len(x) > 0)
clean_twet_texts.count()

# Perform WordCount on the cleaned tweet texts. (note: this is several lines.)
twet_words = clean_twet_texts.flatMap(lambda line: line.split(" "))
twet_tuples  = twet_words.map(lambda word : (word, 1))
wrd_counts = twet_tuples.reduceByKey(lambda a, b :(a + b))

# Create the DataFrame of tweet word counts
tweetDF = sqlContext.createDataFrame(wrd_counts, ["word", "count"])
tweetDF.printSchema()
tweetDF.take(10)

# Join the country and tweet DataFrames (on the appropriate column)
joinedDF = countryDF.alias('c').join(tweetDF.alias('t'),col('c.country') == col('t.word')).select(col('c.code'), col('c.country'), col('t.count'))
joinedDF.printSchema()
joinedDF.take(5)

# Question 1: number of distinct countries mentioned
print("Number of countries mentioned in the tweets:", joinedDF.select('code').distinct().count())

"""##Question 1.1
### Ans: Number of contries mentioned in tweets: 49
"""

# Question 2: number of countries mentioned in tweets.
from pyspark.sql.functions import sum
total = joinedDF.rdd.map(lambda x: (2,x[2])).reduceByKey(lambda x,y: x + y).collect()[0][1]
print("Total number of countries mentioned in tweet:", total)

"""##Question 1.2
### Ans: Total number of time a country is mentioned is 384
"""

# Table 1: top three countries and their counts.
from pyspark.sql.functions import desc
desending = joinedDF.sort(desc("count"))
desending['country', 'count'].show(3)

"""##Question 1.3
###Ans: The 3 most mentioned countries are Nigeria, France and England as shown in table above
"""

df_france = joinedDF.filter(joinedDF.country.isin('France'))
df_france['country', 'count'].show()

"""##Question 1.4
###Ans: France is mentioned 39 times
"""

# Table 2: counts for Wales, Iceland, and Japan.
selected_countries = joinedDF.where((col("country") == "Wales") | (col("country") == "Kenya") | (col("country") == "Netherlands"))
list_desc = selected_countries.sort(desc("count"))
list_desc['country', 'count'].show()

"""##Question 1.5
###Ans: Whales is mentioned the most number of time
"""

joinedDF.agg(avg("count")).first()

"""##Question 2.6
###Ans: Average number of times a country is mentioned is 7.8367
"""